---
title: "Build: Experiment"
description: "The basis of comparing two offers"
icon: "flask"
iconType: "solid"
---

<Frame>
  <img src="/images/HeroExperiments.png" style={{ borderRadius: "0.5rem" }} />
</Frame>
The 1Price platform allows you to create Experiments that compare two [Offerings](/build/offers)
against each other. Experiments are able to have data-driven [Results](/build/results)
that determine the better Offering.

### Experiment Configurations

After setting up your [Offerings](/build/offers) and adding them to an [Experiment](/build/experiment), 1Price will then randomly assign users to a cohort where they will only see only one of the two Offerings.

<Frame>
  <img
    src="/images/ExperimentDashboard.png"
    style={{ borderRadius: "0.5rem" }}
  />
</Frame>

Navigate to the **Dashboard** tab and choose **+ New** then fill in the Experiment Name, Control Offering, Treatment Offering, and the size of the Audience Set. Once you've entered this information, click **Create Experiment**.

<Frame>
  <img src="/images/CreateExperiment.png" style={{ borderRadius: "0.5rem" }} />
</Frame>

### Required Fields

<ParamField path="Experiment Name" type="string" required>
  The name of the experiment
</ParamField>
<ParamField path="Control Offering" type="offer" required>
  The offering that will be used as the Control group
</ParamField>
<ParamField path="Treatment Offering" type="offer" required>
  The offering that will be selected as the Treatment group
</ParamField>
<ParamField path="Audience Set" type="percent" required>
  The % of new customers that will be exposed to the price experiment
</ParamField>

<Tip>
  You can increase the audience set in 10% increments based on how much of your
  audience you want to be exposed to the test. Notably, the test is split evenly
  based on both offerings -- for instance, a test that enrolls 10% Audience Set
  would be 5% Control Offering and 5% Treatment Offering.
</Tip>
<Note>
  Experiments that are localized per country is currently in beta. Interested?
  Request access [here](mailto:hello@1price.co)
</Note>

### Running Multiple Tests Simultaneously

<Note>
  For now you can only do one test at a time. Multiple Tests is currently in
  beta. For early access, request it [here](mailto:hello@1price.co)
</Note>

### Start an Experiment

<Frame>
  <img src="/images/StartExperiment.png" style={{ borderRadius: "0.5rem" }} />
</Frame>

### FAQs

**Can I edit the Offerings in a started experiment?**

Editing an Offering for an active experiment would make the results unusable. Be sure to check before starting your experiment that your chosen Offerings render correctly in your app(s). If you need to make a change to your Offerings, stop the experiment and create a new one with the updated Offerings.

**Can I run multiple experiments simultaneously?**

Yes, as long as they meet the criteria described above.

**Can I add multiple Treatment groups to a single test?**

No, you cannot add multiple Treatment groups to a single test. However, by running multiple tests on the same audience to capture each desired variant you can achieve the same result.

**Can I edit the enrollment criteria of a started experiment?**

Before an experiment has been started, all aspects of enrollment criteria can be edited. However, once an experiment has been started, only new customers to enroll can be edited; since editing the audience that an experiment is exposed to would alter the nature of the test.

**Can I restart an experiment after it's been stopped?**

After you choose to stop an experiment, new customers will no longer be enrolled in it, and it cannot be restarted. If you want to continue a test, create a new experiment and choose the same Offerings as the stopped experiment.

(NOTE: Results for stopped experiments will continue to refresh for 400 days after the experiment has ended)

What happens to customers that were enrolled in an experiment after it's been stopped?

New customers will no longer be enrolled in an experiment after it's been stopped, and customers who were already enrolled in the experiment will begin receiving the Default Offering if they reach a paywall again.

Since we continually refresh results for 400 days after an experiment has been ended, you may see renewals from these customers in your results, since they were enrolled as part of the test while it was running; but new subscriptions started by these customers after the experiment ended and one-time purchases made after the experiment ended will not be included in the results.
